{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filePath): \n",
    "    with open (filePath, 'r') as f: \n",
    "        lines = f.readlines()\n",
    "        text = []\n",
    "        label = []\n",
    "        label_split = []\n",
    "        temp_arr = []\n",
    "        label_split_temp = []\n",
    "        for l in lines: \n",
    "            if l != \"\\n\":\n",
    "                l_split = l.strip().split(\" \")\n",
    "                te = \" \".join(l_split[:-1])\n",
    "                la = l_split[-1]\n",
    "                temp_arr.append((te, la))\n",
    "                label.append(l_split[-1])\n",
    "                label_split_temp.append(l_split[-1])\n",
    "            else: \n",
    "                text.append(temp_arr)\n",
    "                temp_arr = []\n",
    "                label_split.append(label_split_temp)\n",
    "                label_split_temp = []\n",
    "    return text, label, label_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Transition Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_table(text, tra_arr):\n",
    "    for ct, t in enumerate(text): \n",
    "        for ci, i in enumerate(t):\n",
    "            if ci == len(t)-1:\n",
    "                tra_psn = list(final_dict.keys()).index(i[1])\n",
    "                tra_arr[tra_psn][len(final_dict)-1] += 1/final_dict[i[1]]\n",
    "            else:\n",
    "                if ci == 0: \n",
    "                    tra_psn = list(final_dict.keys()).index(i[1])\n",
    "                    tra_arr[0][tra_psn-1] += 1/final_dict['START']\n",
    "                cur_psn = list(final_dict.keys()).index(i[1])  \n",
    "                next_psn = list(final_dict.keys()).index(t[ci+1][1])\n",
    "                tra_arr[cur_psn][next_psn-1] += 1/final_dict[i[1]]\n",
    "    return tra_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filepath, lan):\n",
    "    \n",
    "    em_arr = pd.read_csv(filepath, sep=',',header=None)\n",
    "    em_arr = em_arr.T\n",
    "    em_arr = em_arr.drop([0, 2])\n",
    "    em_arr.columns = em_arr.iloc[0]\n",
    "    em_arr = em_arr[1:]\n",
    "    if lan == 'EN':\n",
    "        em_arr = em_arr.reindex([5,6,11,12,4,7,9,3,16,10,8,19,20,18,21,17,13,22,23,14,15])\n",
    "    elif lan == 'CN':\n",
    "        em_arr = em_arr.reindex([4,6,3,7,8,5,9])\n",
    "    else: \n",
    "         em_arr = em_arr.reindex([6,3,4,7,5,9,8])\n",
    "    header_list = list(em_arr.columns.values)\n",
    "    em = em_arr.drop(['Text'], axis=1).values\n",
    "    em = em.astype('float64')\n",
    "    header_list = header_list[1:]\n",
    "    return em, header_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_index(filepath, header_list):\n",
    "    test = []\n",
    "    output_index = []\n",
    "    output_label = []\n",
    "    index = []\n",
    "    label = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines: \n",
    "            if l != \"\\n\":\n",
    "                label.append(l.strip())\n",
    "                try: \n",
    "                    index.append(header_list.index(l.strip()))\n",
    "                except: \n",
    "                    index.append(header_list.index(\"#UNK#\"))\n",
    "            else: \n",
    "                output_index.append(index)\n",
    "                output_label.append(label)\n",
    "                index = []\n",
    "                label = []\n",
    "    return output_index, output_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Label Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_dict(text, label): \n",
    "    final_dict = {'START': len(text)}\n",
    "    label_counter = dict(Counter(label))\n",
    "    final_dict.update(label_counter)\n",
    "    return final_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Transition Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tra_array(final_dict):\n",
    "    tra_arr = np.zeros((len(final_dict),len(final_dict)))\n",
    "    tra_arr = transition_table(text, tra_arr)\n",
    "    return tra_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertibi Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose\n",
    "\n",
    "def vertibi_algo(tp, ep, d, n):\n",
    "\n",
    "    # get values for first layer \n",
    "    first_arr = []\n",
    "    for i in range(len(tp)-1):\n",
    "        first_arr.append(tp[0][i] * ep[i][n[0]])\n",
    "\n",
    "    # moving forward\n",
    "    pi_arr = [] # store overall array\n",
    "    dy_arr = [] # store array for each layer\n",
    "    for c, i in enumerate(n):\n",
    "        if c == 0:\n",
    "            pass\n",
    "        # second layer, use values from first layer\n",
    "        elif c == 1: \n",
    "            for j in range(len(ep)): # the state\n",
    "                temp_arr = []\n",
    "                temp_dict = {}\n",
    "                for q in range(len(ep)): # the previous state\n",
    "                    temp_arr.append(first_arr[q] * tp[q+1][j] * ep[j][i])\n",
    "                max_val = max(temp_arr)\n",
    "                prev_max = list(d.keys())[temp_arr.index(max(temp_arr))+1]\n",
    "                temp_dict[prev_max] = max_val\n",
    "                temp_arr[temp_arr.index(max(temp_arr))] = -1\n",
    "                max_val = max(temp_arr)\n",
    "                prev_max = list(d.keys())[temp_arr.index(max(temp_arr))+1]\n",
    "                temp_dict[prev_max] = max_val\n",
    "                temp_arr[temp_arr.index(max(temp_arr))] = -1\n",
    "                max_val = max(temp_arr)\n",
    "                prev_max = list(d.keys())[temp_arr.index(max(temp_arr))+1]\n",
    "                temp_dict[prev_max] = max_val\n",
    "                dy_arr.append(temp_dict)\n",
    "            pi_arr.append(dy_arr)\n",
    "        # third layer onwards\n",
    "        else:\n",
    "            layer_arr = []\n",
    "            for j in range(len(ep)): # the state\n",
    "                temp_arr = []\n",
    "                temp_dict = {}\n",
    "                # dy stores list from previous layer\n",
    "                for q in range(len(ep)): # the previous state\n",
    "                    for w in range(3): # the three values in the previous state\n",
    "                        val = list(dy_arr[q].values())[w] * tp[q+1][j] * ep[j][i]\n",
    "                        temp_arr.append(val)\n",
    "                max_val = max(temp_arr)\n",
    "                prev_max = list(d.keys())[temp_arr.index(max(temp_arr))//3+1]\n",
    "                temp_dict[prev_max] = max_val\n",
    "                temp_arr[temp_arr.index(max(temp_arr))] = -1\n",
    "                max_val = max(temp_arr)\n",
    "                prev_max = list(d.keys())[temp_arr.index(max(temp_arr))//3+1]\n",
    "                if prev_max in temp_dict:\n",
    "                    temp_dict[prev_max+'1'] = max_val\n",
    "                else: \n",
    "                    temp_dict[prev_max] = max_val\n",
    "                temp_arr[temp_arr.index(max(temp_arr))] = -1\n",
    "                max_val = max(temp_arr)\n",
    "                prev_max = list(d.keys())[temp_arr.index(max(temp_arr))//3+1]\n",
    "                if prev_max in temp_dict:\n",
    "                    temp_dict[prev_max+'2'] = max_val\n",
    "                else: \n",
    "                    temp_dict[prev_max] = max_val\n",
    "                layer_arr.append(temp_dict)\n",
    "            dy_arr = layer_arr\n",
    "            pi_arr.append(layer_arr)\n",
    "    \n",
    "    # stop layer\n",
    "    last_arr = []\n",
    "    for j in range(len(ep)): # the previous state\n",
    "        for q in range(3): # 2 values in each state\n",
    "            last_arr.append(list(dy_arr[j].values())[q] * tp[j+1][-1])\n",
    "    last_arr[last_arr.index(max(last_arr))] = -1\n",
    "    last_arr[last_arr.index(max(last_arr))] = -1\n",
    "    last_stateidx = last_arr.index(max(last_arr)) // 3 #0\n",
    "    last_state = list(d.keys())[last_stateidx+1]\n",
    "    seclast_stateidx = last_arr.index(max(last_arr)) % 3\n",
    "\n",
    "    rst = []\n",
    "    rst.append(list(d.keys())[last_stateidx+1])\n",
    "    prev_state = list(pi_arr[-1][last_stateidx].keys())[seclast_stateidx]\n",
    "    last_val = list(pi_arr[-1][last_stateidx].values())[seclast_stateidx]\n",
    "    if prev_state[-1] == '1' or prev_state[-1] == '2':\n",
    "            prev_state = prev_state[:-1]\n",
    "    rst.append(prev_state)\n",
    "    \n",
    "    tempprev_state = ''\n",
    "    prev_val = 0\n",
    "    for i in range(len(n)-2):\n",
    "        pi_arr.pop(-1)\n",
    "        prev_dict = pi_arr[-1][list(d.keys()).index(prev_state)-1]\n",
    "        if (tp[list(d.keys()).index(prev_state)][list(d.keys()).index(last_state)-1] * ep[list(d.keys()).index(last_state)-1][n[-1-i]]) != 0:\n",
    "            prev_val = last_val / (tp[list(d.keys()).index(prev_state)][list(d.keys()).index(last_state)-1] * ep[list(d.keys()).index(last_state)-1][n[-1-i]])\n",
    "        for j in range(len(prev_dict)):\n",
    "            if isclose(prev_val, list(prev_dict.values())[j], rel_tol=1e-5, abs_tol=0.0):\n",
    "                tempprev_state = list(prev_dict.keys())[j]\n",
    "        if tempprev_state[-1] == '1' or tempprev_state[-1] == '2':\n",
    "            tempprev_state = tempprev_state[:-1]\n",
    "        last_val = prev_val\n",
    "        last_state = prev_state\n",
    "        prev_state = tempprev_state\n",
    "        rst.append(prev_state)\n",
    "        \n",
    "\n",
    "\n",
    "    return(list(reversed(rst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get output (Change file output name here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(tra_arr, em, final_dict, index, label):\n",
    "    seq = []\n",
    "    for ci, i in enumerate(index): \n",
    "        seq_temp = vertibi_algo(tra_arr, em, final_dict, i)\n",
    "        temp_arr = []\n",
    "        for cj, j in enumerate(seq_temp): \n",
    "            temp_arr.append(\"{} {}\".format(label[ci][cj],j))\n",
    "        seq.append(temp_arr)\n",
    "\n",
    "    with open ('dev.p4.out', 'w') as f: \n",
    "        for i in seq: \n",
    "            for j in i: \n",
    "                f.write(j+\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    return \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change File Path Here \n",
    "pre_filepath = '/Users/nicole/Desktop/CN/CN.csv'\n",
    "devin_filepath = '/Users/nicole/Desktop/CN/dev.in'\n",
    "train_filepath = '/Users/nicole/Desktop/CN/train'\n",
    "\n",
    "text, label, label_split = readFile(train_filepath)\n",
    "final_dict = get_label_dict(text, label)\n",
    "tra_arr = get_tra_array(final_dict)\n",
    "em, header_list = preprocess(pre_filepath, 'CN') # Indicate if it is EN/CN/SG\n",
    "index, output_label = get_label_index(devin_filepath, header_list) #dev in\n",
    "\n",
    "\n",
    "# Change output file name in get_output function\n",
    "print(get_output(tra_arr, em, final_dict, index, output_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
