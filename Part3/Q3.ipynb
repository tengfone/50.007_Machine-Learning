{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filePath): \n",
    "    with open (filePath, 'r') as f: \n",
    "        lines = f.readlines()\n",
    "        text = []\n",
    "        label = []\n",
    "        \n",
    "        temp_arr = []\n",
    "        for l in lines: \n",
    "            if l != \"\\n\":\n",
    "                l_split = l.strip().split(\" \")\n",
    "                te = \" \".join(l_split[:-1])\n",
    "                la = l_split[-1]\n",
    "                temp_arr.append((te, la))\n",
    "                label.append(l_split[-1])\n",
    "            else: \n",
    "                text.append(temp_arr)\n",
    "                temp_arr = []\n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_table(text, tra_arr):\n",
    "    for ct, t in enumerate(text): \n",
    "        for ci, i in enumerate(t):\n",
    "            if ci == len(t)-1:\n",
    "                tra_psn = list(final_dict.keys()).index(i[1])\n",
    "                tra_arr[tra_psn][len(final_dict)-1] += 1/final_dict[i[1]]\n",
    "            else:\n",
    "                if ci == 0: \n",
    "                    tra_psn = list(final_dict.keys()).index(i[1])\n",
    "                    tra_arr[0][tra_psn-1] += 1/final_dict['START']\n",
    "                cur_psn = list(final_dict.keys()).index(i[1])  \n",
    "                next_psn = list(final_dict.keys()).index(t[ci+1][1])\n",
    "                tra_arr[cur_psn][next_psn-1] += 1/final_dict[i[1]]\n",
    "    return tra_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertibi_algo(tra_arr, em_arr, final_dict, n): \n",
    "    # forward \n",
    "    rst = []\n",
    "    pi_arr = []\n",
    "    dy_arr = np.ones(em_arr.shape[0]) #[1,1,1]\n",
    "    for c, i in enumerate (n):\n",
    "        if c == 0: \n",
    "            temp_arr = []\n",
    "            for j in range(em_arr.shape[0]):\n",
    "                val = dy_arr[0] * tra_arr [0][j] * em_arr[j][i]\n",
    "                temp_arr.append(val)\n",
    "            pi_arr.append(temp_arr)\n",
    "            dy_arr = temp_arr\n",
    "        else: \n",
    "            temp_arr = [] #1/216, 1/128, 1/72\n",
    "            for a in range(em_arr.shape[0]): # X \n",
    "                pi_temp = []\n",
    "                for b in range(em_arr.shape[0]): # XYZ in X \n",
    "                    pi_temp.append(dy_arr[b]* tra_arr[b+1][a] * em_arr[a][i])\n",
    "                temp_arr.append(max(pi_temp))\n",
    "            pi_arr.append(temp_arr)\n",
    "            dy_arr = temp_arr\n",
    "    #yn to stop\n",
    "    temp_arr = []\n",
    "    for f in range(em_arr.shape[0]):\n",
    "        temp_arr.append(dy_arr[f] * tra_arr[f+1][tra_arr.shape[1]-1])\n",
    "    rst.append(list(final_dict.keys())[np.argmax(temp_arr)+1])    \n",
    "        \n",
    "    idx_last = list(final_dict.keys()).index(rst[0])-1\n",
    "    for i in reversed(range(len(n)-1)):\n",
    "        temp_arr = []\n",
    "        for j in range(em_arr.shape[0]):\n",
    "            temp_arr.append(pi_arr[i][j] * tra_arr[j+1][idx_last])\n",
    "        idx_last = np.argmax(temp_arr)\n",
    "        rst.append(list(final_dict.keys())[idx_last+1])\n",
    "        \n",
    "    return list(reversed(rst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filepath, lan):\n",
    "    \n",
    "    em_arr = pd.read_csv(filepath, sep=',',header=None)\n",
    "#     em_arr = em_arr.T\n",
    "    em_arr = em_arr.drop([0, 2])\n",
    "    em_arr.columns = em_arr.iloc[0]\n",
    "    em_arr = em_arr[1:]\n",
    "    if lan == 'EN':\n",
    "        em_arr = em_arr.reindex([5,6,11,12,4,7,9,3,16,10,8,19,20,18,21,17,13,22,23,14,15])\n",
    "    elif lan == 'CN':\n",
    "        em_arr = em_arr.reindex([4,6,3,7,8,5,9])\n",
    "    else: \n",
    "         em_arr = em_arr.reindex([6,3,4,7,5,9,8])\n",
    "    header_list = list(em_arr.columns.values)\n",
    "    em = em_arr.drop(['Text'], axis=1).values\n",
    "    em = em.astype('float64')\n",
    "    header_list = header_list[1:]\n",
    "    return em, header_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_index(filepath, header_list):\n",
    "    test = []\n",
    "    output_index = []\n",
    "    output_label = []\n",
    "    index = []\n",
    "    label = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines: \n",
    "            if l != \"\\n\":\n",
    "                label.append(l.strip())\n",
    "                try: \n",
    "                    index.append(header_list.index(l.strip()))\n",
    "                except: \n",
    "                    index.append(header_list.index(\"#UNK#\"))\n",
    "            else: \n",
    "                output_index.append(index)\n",
    "                output_label.append(label)\n",
    "                index = []\n",
    "                label = []\n",
    "    return output_index, output_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(tra_arr, em, final_dict, index, label):\n",
    "    seq = []\n",
    "    for ci, i in enumerate(index): \n",
    "        seq_temp = vertibi_algo(tra_arr, em, final_dict, i)\n",
    "        temp_arr = []\n",
    "        for cj, j in enumerate(seq_temp): \n",
    "            temp_arr.append(\"{} {}\".format(label[ci][cj],j))\n",
    "        seq.append(temp_arr)\n",
    "\n",
    "    with open ('dev.p3.out', 'w') as f: \n",
    "        for i in seq: \n",
    "            for j in i: \n",
    "                f.write(j+\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    return \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_dict(text, label): \n",
    "    final_dict = {'START': len(text)}\n",
    "    label_counter = dict(Counter(label))\n",
    "    final_dict.update(label_counter)\n",
    "    return final_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tra_array(final_dict):\n",
    "    tra_arr = np.zeros((len(final_dict),len(final_dict)))\n",
    "    tra_arr = transition_table(text, tra_arr)\n",
    "    return tra_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "pre_filepath = '/Users/geraldlim/Desktop/CN/CN.csv'\n",
    "devin_filepath = '/Users/geraldlim/Desktop/CN/dev.in'\n",
    "train_filepath = '/Users/geraldlim/Desktop/CN/train'\n",
    "text, label = readFile(train_filepath)\n",
    "final_dict = get_label_dict(text, label)\n",
    "tra_arr = get_tra_array(final_dict)\n",
    "em, header_list = preprocess(pre_filepath, 'CN') #CSV\n",
    "index, output_label = get_label_index(devin_filepath, header_list) #dev in\n",
    "print(get_output(tra_arr, em, final_dict, index, output_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
