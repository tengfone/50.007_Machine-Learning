{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tengfone/.pyenv/versions/3.8.5/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_train_pathing = \"/Users/tengfone/Downloads/train\"\n",
    "TF_test_pathing = \"/Users/tengfone/Downloads/dev.in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_train_file(file_path):\n",
    "    with open(file_path) as f_lines:\n",
    "        all_datas = f_lines.read().splitlines()\n",
    "        all_datas[:] = [x for x in all_datas if x]\n",
    "\n",
    "    word_tags = list()\n",
    "    output_word_tags = list()\n",
    "    for i in all_datas:\n",
    "        i = i.split(' ')\n",
    "        word_tags.append(i)\n",
    "        \n",
    "    for i in word_tags:\n",
    "        if(len(i) == 3):\n",
    "            i = [i[0]+i[1],i[2]]\n",
    "            output_word_tags.append(i)\n",
    "        else:\n",
    "            output_word_tags.append(i)\n",
    "    return output_word_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_test_file(file_path):\n",
    "    with open(file_path) as f_lines:\n",
    "        all_datas = f_lines.read().splitlines()\n",
    "\n",
    "    output = list()\n",
    "    para = 0\n",
    "\n",
    "    for i in all_datas:\n",
    "        if i != \"\":\n",
    "            output.append([i, para])\n",
    "        else:\n",
    "            para += 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_train_df(word_tags):\n",
    "    df = pd.DataFrame(word_tags, columns=['Text', 'Labels'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_test_df(list_words):\n",
    "    df = pd.DataFrame(list_words, columns=['Text', 'Paragraph'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emission Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission(train_data):\n",
    "    # Total Number of Labels (DF)\n",
    "    df_num_labels = train_data['Labels'].value_counts().rename_axis('Labels').reset_index(name='CountY')\n",
    "\n",
    "    # Total Number of y -> x\n",
    "    df_emission = train_data.groupby([\"Text\",\"Labels\"]).size().reset_index()\n",
    "    df_emission.columns = [\"Text\", \"Labels\", \"CountY->X\"]\n",
    "\n",
    "    # e(x|y)\n",
    "    emission_output = pd.merge(df_emission,df_num_labels, on = \"Labels\")\n",
    "    emission_output[\"Emission\"] = emission_output[\"CountY->X\"]/emission_output[\"CountY\"]\n",
    "\n",
    "    return emission_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emission Part b (Fix with UNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk(word,list_of_words):\n",
    "    if(word not in list_of_words):\n",
    "        return \"#UNK#\"\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_fix(train_data,test_data,k):\n",
    "    list_of_words = train_data['Text'].to_list()\n",
    "    test_data['Text'] = test_data['Text'].apply(lambda x: replace_unk(x,list_of_words))\n",
    "  \n",
    "  # Total Number of Labels (DF)\n",
    "    df_num_labels = train_data['Labels'].value_counts().rename_axis('Labels').reset_index(name='CountY')\n",
    "\n",
    "  # Total Number of y -> x\n",
    "    df_emission = train_data.groupby([\"Text\",\"Labels\"]).size().reset_index()\n",
    "    df_emission.columns = [\"Text\", \"Labels\", \"CountY->X\"]\n",
    "\n",
    "  # e(x|y)\n",
    "    emission_output = pd.merge(df_emission,df_num_labels, on = \"Labels\")\n",
    "\n",
    "  # Unique Labelsoutlist.append(output)\n",
    "    unique_labels = emission_output.Labels.unique().tolist()\n",
    "    print(emission_output)\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        each_label = unique_labels[i]\n",
    "        print(f\"Running at {each_label}\")\n",
    "        count_y = emission_output[emission_output['Labels']==each_label]['CountY'].values[0]\n",
    "        temp_list = list()\n",
    "        for index, row in test_data.iterrows():\n",
    "            word = row['Text']\n",
    "            if (word == \"#UNK#\"):\n",
    "                output = k/ (count_y + k)\n",
    "                temp_list.append(output)\n",
    "            else:\n",
    "                count_yx = 0\n",
    "                a = emission_output[(emission_output['Text'] == word)]\n",
    "                a2 = a[(a['Labels'] == each_label)]\n",
    "                # a = df.query('Text==@word and Labels==@label')\n",
    "                if (a2.size==0):\n",
    "                    output = 0\n",
    "                    temp_list.append(output)\n",
    "                else:\n",
    "                    a2 = a2['CountY->X'].values[0]\n",
    "                    count_yx = a2\n",
    "                    output = count_yx/(count_y + k)\n",
    "                    temp_list.append(output)\n",
    "        test_data[each_label] = temp_list\n",
    "                    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get new Fixed Emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Text      Labels  CountY->X  CountY\n",
      "0                           !   B-neutral          1   24868\n",
      "1                           \"   B-neutral          4   24868\n",
      "2                     #04-213   B-neutral          1   24868\n",
      "3      #2017TaipeiUniversiade   B-neutral          1   24868\n",
      "4                         #3D   B-neutral          1   24868\n",
      "...                       ...         ...        ...     ...\n",
      "50429                   youuu  B-negative          1    1139\n",
      "50430                zenyatta  B-negative          2    1139\n",
      "50431                   zhong  B-negative          1    1139\n",
      "50432                    zouk  B-negative          1    1139\n",
      "50433                   zubat  B-negative          1    1139\n",
      "\n",
      "[50434 rows x 4 columns]\n",
      "Running at B-neutral\n",
      "Running at I-neutral\n",
      "Running at I-positive\n",
      "Running at O\n",
      "Running at B-positive\n",
      "Running at I-negative\n",
      "Running at B-negative\n"
     ]
    }
   ],
   "source": [
    "k = 0.5\n",
    "# Training\n",
    "train_data = open_train_file(TF_train_pathing)\n",
    "train_data_df = to_train_df(train_data)\n",
    "emitted = emission(train_data_df)\n",
    "\n",
    "# Testing\n",
    "test_data = open_test_file(TF_test_pathing)\n",
    "\n",
    "test_data_df = to_test_df(test_data)\n",
    "emitted_fix = emission_fix(train_data_df,test_data_df,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting Dataframe to Text/max_label/Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = emitted_fix.drop(['Text', 'Paragraph'], axis=1)\n",
    "df2['max_value'] = df2.max(axis=1)\n",
    "df2['max_label'] = df2.idxmax(axis=1)\n",
    "df3 = emitted_fix[['Text']].copy()\n",
    "df3['Paragraph'] = emitted_fix[['Paragraph']].copy()\n",
    "df3['max_label'] = df2[['max_label']].copy()\n",
    "df3 = df3[['Text','max_label','Paragraph']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Text   max_label  Paragraph\n",
      "0      Everything           O          0\n",
      "1          sounds           O          0\n",
      "2          better           O          0\n",
      "3            with           O          0\n",
      "4             the           O          0\n",
      "...           ...         ...        ...\n",
      "34186           @           O       2649\n",
      "34187      Butter  B-positive       2649\n",
      "34188          My           O       2649\n",
      "34189       #UNK#  I-negative       2649\n",
      "34190       #UNK#  I-negative       2649\n",
      "\n",
      "[34191 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Dataframe to list with paragraphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_idx = 0\n",
    "output_list = list()\n",
    "for index, row in df3.iterrows():\n",
    "    word = row['Text']\n",
    "    label = row['max_label']\n",
    "    para = row['Paragraph']\n",
    "    if(para == df3_idx):\n",
    "        one_line = word + \" \" + label\n",
    "        output_list.append([one_line])\n",
    "    else:\n",
    "        one_empty_line = \"\"\n",
    "        output_list.append([one_empty_line])\n",
    "        one_line = word + \" \" + label\n",
    "        output_list.append([one_line])\n",
    "        df3_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dev.prediction','w') as f:\n",
    "    for item in output_list:\n",
    "        for i in item:\n",
    "            f.write(\"%s\\n\" % i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
